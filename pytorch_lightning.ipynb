{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[TUTORIAL 6: BASICS OF GRAPH NEURAL NETWORKS](https://lightning.ai/docs/pytorch/stable/notebooks/course_UvA-DL/06-graph-neural-networks.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (2.2.1)\n",
      "Requirement already satisfied: torchvision in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (0.17.1)\n",
      "Requirement already satisfied: torchaudio in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (2.2.1)\n",
      "Requirement already satisfied: lightning in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (2.2.0.post0)\n",
      "Requirement already satisfied: torchmetrics in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (1.3.1)\n",
      "Requirement already satisfied: filelock in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from torch) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from torch) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.3.101)\n",
      "Requirement already satisfied: numpy in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: PyYAML<8.0,>=5.4 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from lightning) (6.0.1)\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.8.0 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from lightning) (0.10.1)\n",
      "Requirement already satisfied: packaging<25.0,>=20.0 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from lightning) (23.1)\n",
      "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from lightning) (4.65.0)\n",
      "Requirement already satisfied: pytorch-lightning in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from lightning) (2.2.0.post0)\n",
      "Requirement already satisfied: requests in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from fsspec[http]<2025.0,>=2022.5.0->lightning) (2.31.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from fsspec[http]<2025.0,>=2022.5.0->lightning) (3.9.3)\n",
      "Requirement already satisfied: setuptools in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from lightning-utilities<2.0,>=0.8.0->lightning) (68.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (1.9.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (4.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from requests->fsspec[http]<2025.0,>=2022.5.0->lightning) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from requests->fsspec[http]<2025.0,>=2022.5.0->lightning) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from requests->fsspec[http]<2025.0,>=2022.5.0->lightning) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from requests->fsspec[http]<2025.0,>=2022.5.0->lightning) (2024.2.2)\n",
      "Looking in links: https://data.pyg.org/whl/torch-2.2.1+cu121.html\n",
      "Requirement already satisfied: torch-geometric in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (2.5.0)\n",
      "Requirement already satisfied: torch-sparse in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (0.6.18+pt22cu121)\n",
      "Requirement already satisfied: torch-cluster in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (1.6.3+pt22cu121)\n",
      "Requirement already satisfied: torch-scatter in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (2.1.2+pt22cu121)\n",
      "Requirement already satisfied: torch-spline-conv in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (1.2.2+pt22cu121)\n",
      "Requirement already satisfied: tqdm in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from torch-geometric) (4.65.0)\n",
      "Requirement already satisfied: numpy in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from torch-geometric) (1.24.3)\n",
      "Requirement already satisfied: scipy in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from torch-geometric) (1.10.1)\n",
      "Requirement already satisfied: fsspec in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from torch-geometric) (2023.10.0)\n",
      "Requirement already satisfied: jinja2 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from torch-geometric) (3.1.3)\n",
      "Requirement already satisfied: aiohttp in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from torch-geometric) (3.9.3)\n",
      "Requirement already satisfied: requests in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from torch-geometric) (2.31.0)\n",
      "Requirement already satisfied: pyparsing in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from torch-geometric) (3.0.9)\n",
      "Requirement already satisfied: scikit-learn in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from torch-geometric) (1.3.0)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from torch-geometric) (5.9.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from aiohttp->torch-geometric) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from aiohttp->torch-geometric) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from aiohttp->torch-geometric) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from aiohttp->torch-geometric) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from aiohttp->torch-geometric) (1.9.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from aiohttp->torch-geometric) (4.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from jinja2->torch-geometric) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from requests->torch-geometric) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from requests->torch-geometric) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from requests->torch-geometric) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from requests->torch-geometric) (2024.2.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from scikit-learn->torch-geometric) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from scikit-learn->torch-geometric) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchaudio lightning torchmetrics\n",
    "!pip3 install \"torch-geometric\" \"torch-sparse\" \"torch-cluster\" \"torch-scatter\" \"torch-spline-conv\" -f https://data.pyg.org/whl/torch-2.2.1+cu121.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.1+cu121'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import urllib.request\n",
    "from urllib.error import HTTPError\n",
    "\n",
    "import lightning as L\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch_geometric\n",
    "import torch_geometric.data as geom_data\n",
    "import torch_geometric.nn as geom_nn\n",
    "\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "AVAIL_GPUS = min(1, torch.cuda.device_count())\n",
    "BATCH_SIZE = 256 if AVAIL_GPUS else 64\n",
    "# Path to the folder where the datasets are/should be downloaded\n",
    "DATASET_PATH = os.environ.get(\"PATH_DATASETS\", \"data/\")\n",
    "# Path to the folder where the pretrained models are saved\n",
    "CHECKPOINT_PATH = os.environ.get(\"PATH_CHECKPOINT\", \"saved_models/GNNs/\")\n",
    "\n",
    "# Setting the seed\n",
    "L.seed_everything(42)\n",
    "\n",
    "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial7/NodeLevelMLP.ckpt...\n",
      "Downloading https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial7/NodeLevelGNN.ckpt...\n",
      "Downloading https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial7/GraphLevelGraphConv.ckpt...\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial7/\"\n",
    "# Files to download\n",
    "pretrained_files = [\"NodeLevelMLP.ckpt\", \"NodeLevelGNN.ckpt\", \"GraphLevelGraphConv.ckpt\"]\n",
    "\n",
    "# Create checkpoint path if it doesn't exist yet\n",
    "os.makedirs(CHECKPOINT_PATH, exist_ok=True)\n",
    "\n",
    "# For each file, check whether it already exists. If not, try downloading it.\n",
    "for file_name in pretrained_files:\n",
    "    file_path = os.path.join(CHECKPOINT_PATH, file_name)\n",
    "    if \"/\" in file_name:\n",
    "        os.makedirs(file_path.rsplit(\"/\", 1)[0], exist_ok=True)\n",
    "    if not os.path.isfile(file_path):\n",
    "        file_url = base_url + file_name\n",
    "        print(\"Downloading %s...\" % file_url)\n",
    "        try:\n",
    "            urllib.request.urlretrieve(file_url, file_path)\n",
    "        except HTTPError as e:\n",
    "            print(\n",
    "                \"Something went wrong. Please try to download the file from the GDrive folder,\"\n",
    "                \" or contact the author with the full output including the following error:\\n\",\n",
    "                e,\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNLayer(nn.Module):\n",
    "    def __init__(self, c_in, c_out):\n",
    "        super().__init__()\n",
    "        self.projection = nn.Linear(c_in, c_out)\n",
    "\n",
    "    def forward(self, node_feats, adj_matrix):\n",
    "        \"\"\"Forward.\n",
    "\n",
    "        Args:\n",
    "            node_feats: Tensor with node features of shape [batch_size, num_nodes, c_in]\n",
    "            adj_matrix: Batch of adjacency matrices of the graph. If there is an edge from i to j,\n",
    "                         adj_matrix[b,i,j]=1 else 0. Supports directed edges by non-symmetric matrices.\n",
    "                         Assumes to already have added the identity connections.\n",
    "                         Shape: [batch_size, num_nodes, num_nodes]\n",
    "        \"\"\"\n",
    "        # Num neighbours = number of incoming edges\n",
    "        num_neighbours = adj_matrix.sum(dim=-1, keepdims=True)\n",
    "        node_feats = self.projection(node_feats)\n",
    "        node_feats = torch.bmm(adj_matrix, node_feats) # バッチごとの行列の積\n",
    "        node_feats = node_feats / num_neighbours\n",
    "        return node_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node features:\n",
      " tensor([[[0., 1.],\n",
      "         [2., 3.],\n",
      "         [4., 5.],\n",
      "         [6., 7.]]])\n",
      "\n",
      "Adjacency matrix:\n",
      " tensor([[[1., 1., 0., 0.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [0., 1., 1., 1.],\n",
      "         [0., 1., 1., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "node_feats = torch.arange(8, dtype=torch.float32).view(1, 4, 2)\n",
    "adj_matrix = Tensor([[\n",
    "    [1, 1, 0, 0], \n",
    "    [1, 1, 1, 1], \n",
    "    [0, 1, 1, 1], \n",
    "    [0, 1, 1, 1]]\n",
    "])\n",
    "\n",
    "print(\"Node features:\\n\", node_feats)\n",
    "print(\"\\nAdjacency matrix:\\n\", adj_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjacency matrix tensor([[[1., 1., 0., 0.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [0., 1., 1., 1.],\n",
      "         [0., 1., 1., 1.]]])\n",
      "Input features tensor([[[0., 1.],\n",
      "         [2., 3.],\n",
      "         [4., 5.],\n",
      "         [6., 7.]]])\n",
      "Output features tensor([[[1., 2.],\n",
      "         [3., 4.],\n",
      "         [4., 5.],\n",
      "         [4., 5.]]])\n"
     ]
    }
   ],
   "source": [
    "layer = GCNLayer(c_in=2, c_out=2)\n",
    "layer.projection.weight.data = Tensor([[1.0, 0.0], [0.0, 1.0]])\n",
    "layer.projection.bias.data = Tensor([0.0, 0.0])\n",
    "\n",
    "with torch.no_grad():\n",
    "    out_feats = layer(node_feats, adj_matrix)\n",
    "\n",
    "print(\"Adjacency matrix\", adj_matrix)\n",
    "print(\"Input features\", node_feats)\n",
    "print(\"Output features\", out_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATLayer(nn.Module):\n",
    "    def __init__(self, c_in, c_out, num_heads=1, concat_heads=True, alpha=0.2):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            c_in: Dimensionality of input features\n",
    "            c_out: Dimensionality of output features\n",
    "            num_heads: Number of heads, i.e. attention mechanisms to apply in parallel. The\n",
    "                        output features are equally split up over the heads if concat_heads=True.\n",
    "            concat_heads: If True, the output of the different heads is concatenated instead of averaged.\n",
    "            alpha: Negative slope of the LeakyReLU activation.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.concat_heads = concat_heads\n",
    "        if self.concat_heads:\n",
    "            assert c_out % num_heads == 0, \"Number of output features must be a multiple of the count of heads.\"\n",
    "            c_out = c_out // num_heads\n",
    "\n",
    "        # Sub-modules and parameters needed in the layer\n",
    "        self.projection = nn.Linear(c_in, c_out * num_heads)\n",
    "        self.a = nn.Parameter(Tensor(num_heads, 2 * c_out))  # One per head\n",
    "        self.leakyrelu = nn.LeakyReLU(alpha)\n",
    "\n",
    "        # Initialization from the original implementation\n",
    "        nn.init.xavier_uniform_(self.projection.weight.data, gain=1.414)\n",
    "        nn.init.xavier_uniform_(self.a.data, gain=1.414)\n",
    "\n",
    "    def forward(self, node_feats, adj_matrix, print_attn_probs=False):\n",
    "        \"\"\"Forward.\n",
    "\n",
    "        Args:\n",
    "            node_feats: Input features of the node. Shape: [batch_size, c_in]\n",
    "            adj_matrix: Adjacency matrix including self-connections. Shape: [batch_size, num_nodes, num_nodes]\n",
    "            print_attn_probs: If True, the attention weights are printed during the forward pass\n",
    "                               (for debugging purposes)\n",
    "        \"\"\"\n",
    "        batch_size, num_nodes = node_feats.size(0), node_feats.size(1)\n",
    "\n",
    "        # Apply linear layer and sort nodes by head\n",
    "        node_feats = self.projection(node_feats)\n",
    "        node_feats = node_feats.view(batch_size, num_nodes, self.num_heads, -1)\n",
    "\n",
    "        # We need to calculate the attention logits for every edge in the adjacency matrix\n",
    "        # Doing this on all possible combinations of nodes is very expensive\n",
    "        # => Create a tensor of [W*h_i||W*h_j] with i and j being the indices of all edges\n",
    "        # Returns indices where the adjacency matrix is not 0 => edges\n",
    "        edges = adj_matrix.nonzero(as_tuple=False)\n",
    "        node_feats_flat = node_feats.view(batch_size * num_nodes, self.num_heads, -1)\n",
    "        edge_indices_row = edges[:, 0] * num_nodes + edges[:, 1]\n",
    "        edge_indices_col = edges[:, 0] * num_nodes + edges[:, 2]\n",
    "        a_input = torch.cat(\n",
    "            [\n",
    "                torch.index_select(input=node_feats_flat, index=edge_indices_row, dim=0),\n",
    "                torch.index_select(input=node_feats_flat, index=edge_indices_col, dim=0),\n",
    "            ],\n",
    "            dim=-1,\n",
    "        )  # Index select returns a tensor with node_feats_flat being indexed at the desired positions\n",
    "\n",
    "        # Calculate attention MLP output (independent for each head)\n",
    "        attn_logits = torch.einsum(\"bhc,hc->bh\", a_input, self.a)\n",
    "        attn_logits = self.leakyrelu(attn_logits)\n",
    "\n",
    "        # Map list of attention values back into a matrix\n",
    "        attn_matrix = attn_logits.new_zeros(adj_matrix.shape + (self.num_heads,)).fill_(-9e15)\n",
    "        attn_matrix[adj_matrix[..., None].repeat(1, 1, 1, self.num_heads) == 1] = attn_logits.reshape(-1)\n",
    "\n",
    "        # Weighted average of attention\n",
    "        attn_probs = F.softmax(attn_matrix, dim=2)\n",
    "        if print_attn_probs:\n",
    "            print(\"Attention probs\\n\", attn_probs.permute(0, 3, 1, 2))\n",
    "        node_feats = torch.einsum(\"bijh,bjhc->bihc\", attn_probs, node_feats)\n",
    "\n",
    "        # If heads should be concatenated, we can do this by reshaping. Otherwise, take mean\n",
    "        if self.concat_heads:\n",
    "            node_feats = node_feats.reshape(batch_size, num_nodes, -1)\n",
    "        else:\n",
    "            node_feats = node_feats.mean(dim=2)\n",
    "\n",
    "        return node_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention probs\n",
      " tensor([[[[0.3543, 0.6457, 0.0000, 0.0000],\n",
      "          [0.1096, 0.1450, 0.2642, 0.4813],\n",
      "          [0.0000, 0.1858, 0.2885, 0.5257],\n",
      "          [0.0000, 0.2391, 0.2696, 0.4913]],\n",
      "\n",
      "         [[0.5100, 0.4900, 0.0000, 0.0000],\n",
      "          [0.2975, 0.2436, 0.2340, 0.2249],\n",
      "          [0.0000, 0.3838, 0.3142, 0.3019],\n",
      "          [0.0000, 0.4018, 0.3289, 0.2693]]]])\n",
      "Adjacency matrix tensor([[[1., 1., 0., 0.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [0., 1., 1., 1.],\n",
      "         [0., 1., 1., 1.]]])\n",
      "Input features tensor([[[0., 1.],\n",
      "         [2., 3.],\n",
      "         [4., 5.],\n",
      "         [6., 7.]]])\n",
      "Output features tensor([[[1.2913, 1.9800],\n",
      "         [4.2344, 3.7725],\n",
      "         [4.6798, 4.8362],\n",
      "         [4.5043, 4.7351]]])\n"
     ]
    }
   ],
   "source": [
    "layer = GATLayer(2, 2, num_heads=2)\n",
    "layer.projection.weight.data = Tensor([[1.0, 0.0], [0.0, 1.0]])\n",
    "layer.projection.bias.data = Tensor([0.0, 0.0])\n",
    "layer.a.data = Tensor([[-0.2, 0.3], [0.1, -0.1]])\n",
    "\n",
    "with torch.no_grad():\n",
    "    out_feats = layer(node_feats, adj_matrix, print_attn_probs=True)\n",
    "\n",
    "print(\"Adjacency matrix\", adj_matrix)\n",
    "print(\"Input features\", node_feats)\n",
    "print(\"Output features\", out_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn_layer_by_name = {\"GCN\": geom_nn.GCNConv, \"GAT\": geom_nn.GATConv, \"GraphConv\": geom_nn.GraphConv}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node-level tasks: Semi-supervised node classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "cora_dataset = torch_geometric.datasets.Planetoid(root=DATASET_PATH, name=\"Cora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cora_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        c_in,\n",
    "        c_hidden,\n",
    "        c_out,\n",
    "        num_layers=2,\n",
    "        layer_name=\"GCN\",\n",
    "        dp_rate=0.1,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"GNNModel.\n",
    "\n",
    "        Args:\n",
    "            c_in: Dimension of input features\n",
    "            c_hidden: Dimension of hidden features\n",
    "            c_out: Dimension of the output features. Usually number of classes in classification\n",
    "            num_layers: Number of \"hidden\" graph layers\n",
    "            layer_name: String of the graph layer to use\n",
    "            dp_rate: Dropout rate to apply throughout the network\n",
    "            kwargs: Additional arguments for the graph layer (e.g. number of heads for GAT)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        gnn_layer = gnn_layer_by_name[layer_name]\n",
    "\n",
    "        layers = []\n",
    "        in_channels, out_channels = c_in, c_hidden\n",
    "        for l_idx in range(num_layers - 1):\n",
    "            layers += [\n",
    "                gnn_layer(in_channels=in_channels, out_channels=out_channels, **kwargs),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(dp_rate),\n",
    "            ]\n",
    "            in_channels = c_hidden\n",
    "        layers += [gnn_layer(in_channels=in_channels, out_channels=c_out, **kwargs)]\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        \"\"\"Forward.\n",
    "\n",
    "        Args:\n",
    "            x: Input features per node\n",
    "            edge_index: List of vertex index pairs representing the edges in the graph (PyTorch geometric notation)\n",
    "        \"\"\"\n",
    "        for layer in self.layers:\n",
    "            # For graph layers, we need to add the \"edge_index\" tensor as additional input\n",
    "            # All PyTorch Geometric graph layer inherit the class \"MessagePassing\", hence\n",
    "            # we can simply check the class type.\n",
    "            if isinstance(layer, geom_nn.MessagePassing):\n",
    "                x = layer(x, edge_index)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nodeごとに独立したMLPを作り、ベースラインとする\n",
    "class MLPModel(nn.Module):\n",
    "    def __init__(self, c_in, c_hidden, c_out, num_layers=2, dp_rate=0.1):\n",
    "        \"\"\"MLPModel.\n",
    "\n",
    "        Args:\n",
    "            c_in: Dimension of input features\n",
    "            c_hidden: Dimension of hidden features\n",
    "            c_out: Dimension of the output features. Usually number of classes in classification\n",
    "            num_layers: Number of hidden layers\n",
    "            dp_rate: Dropout rate to apply throughout the network\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        in_channels, out_channels = c_in, c_hidden\n",
    "        for l_idx in range(num_layers - 1):\n",
    "            layers += [nn.Linear(in_channels, out_channels), nn.ReLU(inplace=True), nn.Dropout(dp_rate)]\n",
    "            in_channels = c_hidden\n",
    "        layers += [nn.Linear(in_channels, c_out)]\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, *args, **kwargs):\n",
    "        \"\"\"Forward.\n",
    "\n",
    "        Args:\n",
    "            x: Input features per node\n",
    "        \"\"\"\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeLevelGNN(L.LightningModule):\n",
    "    def __init__(self, model_name, **model_kwargs):\n",
    "        super().__init__()\n",
    "        # Saving hyperparameters\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        if model_name == \"MLP\":\n",
    "            self.model = MLPModel(**model_kwargs)\n",
    "        else:\n",
    "            self.model = GNNModel(**model_kwargs)\n",
    "        self.loss_module = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, data, mode=\"train\"):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.model(x, edge_index)\n",
    "\n",
    "        # Only calculate the loss on the nodes corresponding to the mask\n",
    "        if mode == \"train\":\n",
    "            mask = data.train_mask\n",
    "        elif mode == \"val\":\n",
    "            mask = data.val_mask\n",
    "        elif mode == \"test\":\n",
    "            mask = data.test_mask\n",
    "        else:\n",
    "            assert False, \"Unknown forward mode: %s\" % mode\n",
    "\n",
    "        loss = self.loss_module(x[mask], data.y[mask])\n",
    "        acc = (x[mask].argmax(dim=-1) == data.y[mask]).sum().float() / mask.sum()\n",
    "        return loss, acc\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # We use SGD here, but Adam works as well\n",
    "        optimizer = optim.SGD(self.parameters(), lr=0.1, momentum=0.9, weight_decay=2e-3)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, acc = self.forward(batch, mode=\"train\")\n",
    "        self.log(\"train_loss\", loss)\n",
    "        self.log(\"train_acc\", acc)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        _, acc = self.forward(batch, mode=\"val\")\n",
    "        self.log(\"val_acc\", acc)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        _, acc = self.forward(batch, mode=\"test\")\n",
    "        self.log(\"test_acc\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_node_classifier(model_name, dataset, **model_kwargs):\n",
    "    L.seed_everything(42)\n",
    "    node_data_loader = geom_data.DataLoader(dataset, batch_size=1)\n",
    "\n",
    "    # Create a PyTorch Lightning trainer\n",
    "    root_dir = os.path.join(CHECKPOINT_PATH, \"NodeLevel\" + model_name)\n",
    "    os.makedirs(root_dir, exist_ok=True)\n",
    "    trainer = L.Trainer(\n",
    "        default_root_dir=root_dir,\n",
    "        callbacks=[ModelCheckpoint(save_weights_only=True, mode=\"max\", monitor=\"val_acc\")],\n",
    "        accelerator=\"auto\",\n",
    "        devices=AVAIL_GPUS,\n",
    "        max_epochs=200,\n",
    "        enable_progress_bar=False,\n",
    "    )  # 0 because epoch size is 1\n",
    "    trainer.logger._default_hp_metric = None  # Optional logging argument that we don't need\n",
    "\n",
    "    # Check whether pretrained model exists. If yes, load it and skip training\n",
    "    pretrained_filename = os.path.join(CHECKPOINT_PATH, \"NodeLevel%s.ckpt\" % model_name)\n",
    "    if os.path.isfile(pretrained_filename):\n",
    "        print(\"Found pretrained model, loading...\")\n",
    "        model = NodeLevelGNN.load_from_checkpoint(pretrained_filename)\n",
    "    else:\n",
    "        L.seed_everything()\n",
    "        model = NodeLevelGNN(\n",
    "            model_name=model_name, c_in=dataset.num_node_features, c_out=dataset.num_classes, **model_kwargs\n",
    "        )\n",
    "        trainer.fit(model, node_data_loader, node_data_loader)\n",
    "        model = NodeLevelGNN.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)\n",
    "\n",
    "    # Test best model on the test set\n",
    "    test_result = trainer.test(model, dataloaders=node_data_loader, verbose=False)\n",
    "    batch = next(iter(node_data_loader))\n",
    "    batch = batch.to(model.device)\n",
    "    _, train_acc = model.forward(batch, mode=\"train\")\n",
    "    _, val_acc = model.forward(batch, mode=\"val\")\n",
    "    result = {\"train\": train_acc, \"val\": val_acc, \"test\": test_result[0][\"test_acc\"]}\n",
    "    return model, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small function for printing the test scores\n",
    "def print_results(result_dict):\n",
    "    if \"train\" in result_dict:\n",
    "        print(\"Train accuracy: %4.2f%%\" % (100.0 * result_dict[\"train\"]))\n",
    "    if \"val\" in result_dict:\n",
    "        print(\"Val accuracy:   %4.2f%%\" % (100.0 * result_dict[\"val\"]))\n",
    "    print(\"Test accuracy:  %4.2f%%\" % (100.0 * result_dict[\"test\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found pretrained model, loading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.0.2 to v2.2.0.post0. To apply the upgrade to your files permanently, run `python -m lightning.pytorch.utilities.upgrade_checkpoint saved_models/GNNs/NodeLevelMLP.ckpt`\n",
      "Missing logger folder: saved_models/GNNs/NodeLevelMLP/lightning_logs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 97.14%\n",
      "Val accuracy:   54.60%\n",
      "Test accuracy:  60.60%\n"
     ]
    }
   ],
   "source": [
    "node_mlp_model, node_mlp_result = train_node_classifier(\n",
    "    model_name=\"MLP\", dataset=cora_dataset, c_hidden=16, num_layers=2, dp_rate=0.1\n",
    ")\n",
    "\n",
    "print_results(node_mlp_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.0.2 to v2.2.0.post0. To apply the upgrade to your files permanently, run `python -m lightning.pytorch.utilities.upgrade_checkpoint saved_models/GNNs/NodeLevelGNN.ckpt`\n",
      "Missing logger folder: saved_models/GNNs/NodeLevelGNN/lightning_logs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found pretrained model, loading...\n",
      "Train accuracy: 100.00%\n",
      "Val accuracy:   78.60%\n",
      "Test accuracy:  82.40%\n"
     ]
    }
   ],
   "source": [
    "node_gnn_model, node_gnn_result = train_node_classifier(\n",
    "    model_name=\"GNN\", layer_name=\"GCN\", dataset=cora_dataset, c_hidden=16, num_layers=2, dp_rate=0.1\n",
    ")\n",
    "print_results(node_gnn_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph-level tasks: Graph classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- グラフ全体を見て分類を行う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data object: Data(x=[3371, 7], edge_index=[2, 7442], edge_attr=[7442, 4], y=[188])\n",
      "Length: 188\n",
      "Average label: 0.66\n"
     ]
    }
   ],
   "source": [
    "tu_dataset = torch_geometric.datasets.TUDataset(root=DATASET_PATH, name=\"MUTAG\")\n",
    "print(\"Data object:\", tu_dataset.data)\n",
    "print(\"Length:\", len(tu_dataset))\n",
    "print(\"Average label: %4.2f\" % (tu_dataset.data.y.float().mean().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: DataBatch(edge_index=[2, 1512], x=[687, 7], edge_attr=[1512, 4], y=[38], batch=[687], ptr=[39])\n",
      "Labels: tensor([1, 1, 1, 0, 0, 0, 1, 1, 1, 0])\n",
      "Batch indices: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "tu_dataset.shuffle()\n",
    "train_dataset = tu_dataset[:150]\n",
    "test_dataset = tu_dataset[150:]\n",
    "\n",
    "graph_train_loader = geom_data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "graph_val_loader = geom_data.DataLoader(test_dataset, batch_size=BATCH_SIZE)  # Additional loader for a larger datasets\n",
    "graph_test_loader = geom_data.DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "batch = next(iter(graph_test_loader))\n",
    "print(\"Batch:\", batch)\n",
    "print(\"Labels:\", batch.y[:10])\n",
    "print(\"Batch indices:\", batch.batch[:40])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- バッチ化するときに、それぞれのグラフは異なるノード数を持つため、パディングが必要となる\n",
    "- => 隣接行列と特徴ベクトルをかけ合わせて、一つのグラフ大きなとして扱う\n",
    "- それぞれのグラフにはエッジが存在しないため、GNNはそれぞれのグラフに対して処理を行う場合と同じ結果を出力できる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphGNNModel(nn.Module):\n",
    "    def __init__(self, c_in, c_hidden, c_out, dp_rate_linear=0.5, **kwargs):\n",
    "        \"\"\"GraphGNNModel.\n",
    "\n",
    "        Args:\n",
    "            c_in: Dimension of input features\n",
    "            c_hidden: Dimension of hidden features\n",
    "            c_out: Dimension of output features (usually number of classes)\n",
    "            dp_rate_linear: Dropout rate before the linear layer (usually much higher than inside the GNN)\n",
    "            kwargs: Additional arguments for the GNNModel object\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.GNN = GNNModel(c_in=c_in, c_hidden=c_hidden, c_out=c_hidden, **kwargs)  # Not our prediction output yet!\n",
    "        self.head = nn.Sequential(nn.Dropout(dp_rate_linear), nn.Linear(c_hidden, c_out))\n",
    "\n",
    "    def forward(self, x, edge_index, batch_idx):\n",
    "        \"\"\"Forward.\n",
    "\n",
    "        Args:\n",
    "            x: Input features per node\n",
    "            edge_index: List of vertex index pairs representing the edges in the graph (PyTorch geometric notation)\n",
    "            batch_idx: Index of batch element for each node\n",
    "        \"\"\"\n",
    "        x = self.GNN(x, edge_index)\n",
    "        x = geom_nn.global_mean_pool(x, batch_idx)  # Average pooling\n",
    "        x = self.head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphLevelGNN(L.LightningModule):\n",
    "    def __init__(self, **model_kwargs):\n",
    "        super().__init__()\n",
    "        # Saving hyperparameters\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.model = GraphGNNModel(**model_kwargs)\n",
    "        self.loss_module = nn.BCEWithLogitsLoss() if self.hparams.c_out == 1 else nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, data, mode=\"train\"):\n",
    "        x, edge_index, batch_idx = data.x, data.edge_index, data.batch\n",
    "        x = self.model(x, edge_index, batch_idx)\n",
    "        x = x.squeeze(dim=-1)\n",
    "\n",
    "        if self.hparams.c_out == 1:\n",
    "            preds = (x > 0).float()\n",
    "            data.y = data.y.float()\n",
    "        else:\n",
    "            preds = x.argmax(dim=-1)\n",
    "        loss = self.loss_module(x, data.y)\n",
    "        acc = (preds == data.y).sum().float() / preds.shape[0]\n",
    "        return loss, acc\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # High lr because of small dataset and small model\n",
    "        optimizer = optim.AdamW(self.parameters(), lr=1e-2, weight_decay=0.0)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, acc = self.forward(batch, mode=\"train\")\n",
    "        self.log(\"train_loss\", loss)\n",
    "        self.log(\"train_acc\", acc)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        _, acc = self.forward(batch, mode=\"val\")\n",
    "        self.log(\"val_acc\", acc)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        _, acc = self.forward(batch, mode=\"test\")\n",
    "        self.log(\"test_acc\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_graph_classifier(model_name, **model_kwargs):\n",
    "    L.seed_everything(42)\n",
    "\n",
    "    # Create a PyTorch Lightning trainer with the generation callback\n",
    "    root_dir = os.path.join(CHECKPOINT_PATH, \"GraphLevel\" + model_name)\n",
    "    os.makedirs(root_dir, exist_ok=True)\n",
    "    trainer = L.Trainer(\n",
    "        default_root_dir=root_dir,\n",
    "        callbacks=[ModelCheckpoint(save_weights_only=True, mode=\"max\", monitor=\"val_acc\")],\n",
    "        accelerator=\"cuda\",\n",
    "        devices=AVAIL_GPUS,\n",
    "        max_epochs=500,\n",
    "        enable_progress_bar=False,\n",
    "    )\n",
    "    trainer.logger._default_hp_metric = None\n",
    "\n",
    "    # Check whether pretrained model exists. If yes, load it and skip training\n",
    "    pretrained_filename = os.path.join(CHECKPOINT_PATH, \"GraphLevel%s.ckpt\" % model_name)\n",
    "    if os.path.isfile(pretrained_filename):\n",
    "        print(\"Found pretrained model, loading...\")\n",
    "        model = GraphLevelGNN.load_from_checkpoint(pretrained_filename)\n",
    "    else:\n",
    "        L.seed_everything(42)\n",
    "        model = GraphLevelGNN(\n",
    "            c_in=tu_dataset.num_node_features,\n",
    "            c_out=1 if tu_dataset.num_classes == 2 else tu_dataset.num_classes,\n",
    "            **model_kwargs,\n",
    "        )\n",
    "        trainer.fit(model, graph_train_loader, graph_val_loader)\n",
    "        model = GraphLevelGNN.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)\n",
    "\n",
    "    # Test best model on validation and test set\n",
    "    train_result = trainer.test(model, dataloaders=graph_train_loader, verbose=False)\n",
    "    test_result = trainer.test(model, dataloaders=graph_test_loader, verbose=False)\n",
    "    result = {\"test\": test_result[0][\"test_acc\"], \"train\": train_result[0][\"test_acc\"]}\n",
    "    return model, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type              | Params\n",
      "--------------------------------------------------\n",
      "0 | model       | GraphGNNModel     | 266 K \n",
      "1 | loss_module | BCEWithLogitsLoss | 0     \n",
      "--------------------------------------------------\n",
      "266 K     Trainable params\n",
      "0         Non-trainable params\n",
      "266 K     Total params\n",
      "1.067     Total estimated model params size (MB)\n",
      "/home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n",
      "/home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n",
      "/home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "`Trainer.fit` stopped: `max_epochs=500` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    }
   ],
   "source": [
    "model, result = train_graph_classifier(\n",
    "    model_name=\"GraphConv\", c_hidden=256, layer_name=\"GraphConv\", num_layers=3, dp_rate_linear=0.5, dp_rate=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train performance: 90.67%\n",
      "Test performance:  89.47%\n"
     ]
    }
   ],
   "source": [
    "print(\"Train performance: %4.2f%%\" % (100.0 * result[\"train\"]))\n",
    "print(\"Test performance:  %4.2f%%\" % (100.0 * result[\"test\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_nlp_lstm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
