{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[TUTORIAL 6: BASICS OF GRAPH NEURAL NETWORKS](https://lightning.ai/docs/pytorch/stable/notebooks/course_UvA-DL/06-graph-neural-networks.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-2.2.1-cp38-cp38-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.17.1-cp38-cp38-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting torchaudio\n",
      "  Using cached torchaudio-2.2.1-cp38-cp38-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting lightning\n",
      "  Using cached lightning-2.2.0.post0-py3-none-any.whl.metadata (56 kB)\n",
      "Collecting torchmetrics\n",
      "  Using cached torchmetrics-1.3.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from torch) (2023.10.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
      "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
      "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
      "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
      "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
      "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
      "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.19.3 (from torch)\n",
      "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==2.2.0 (from torch)\n",
      "  Using cached triton-2.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: numpy in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: PyYAML<8.0,>=5.4 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from lightning) (6.0.1)\n",
      "Collecting lightning-utilities<2.0,>=0.8.0 (from lightning)\n",
      "  Using cached lightning_utilities-0.10.1-py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: packaging<25.0,>=20.0 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from lightning) (23.1)\n",
      "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from lightning) (4.65.0)\n",
      "Collecting pytorch-lightning (from lightning)\n",
      "  Using cached pytorch_lightning-2.2.0.post0-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: requests in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from fsspec[http]<2025.0,>=2022.5.0->lightning) (2.31.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from fsspec[http]<2025.0,>=2022.5.0->lightning) (3.9.3)\n",
      "Requirement already satisfied: setuptools in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from lightning-utilities<2.0,>=0.8.0->lightning) (68.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (1.9.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (4.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from requests->fsspec[http]<2025.0,>=2022.5.0->lightning) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from requests->fsspec[http]<2025.0,>=2022.5.0->lightning) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from requests->fsspec[http]<2025.0,>=2022.5.0->lightning) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from requests->fsspec[http]<2025.0,>=2022.5.0->lightning) (2024.2.2)\n",
      "Using cached torch-2.2.1-cp38-cp38-manylinux1_x86_64.whl (755.5 MB)\n",
      "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
      "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Using cached triton-2.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
      "Using cached torchvision-0.17.1-cp38-cp38-manylinux1_x86_64.whl (6.9 MB)\n",
      "Using cached torchaudio-2.2.1-cp38-cp38-manylinux1_x86_64.whl (3.3 MB)\n",
      "Using cached lightning-2.2.0.post0-py3-none-any.whl (2.1 MB)\n",
      "Using cached torchmetrics-1.3.1-py3-none-any.whl (840 kB)\n",
      "Using cached lightning_utilities-0.10.1-py3-none-any.whl (24 kB)\n",
      "Using cached pytorch_lightning-2.2.0.post0-py3-none-any.whl (800 kB)\n",
      "Using cached nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (20.5 MB)\n",
      "Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, torchmetrics, torchaudio, pytorch-lightning, lightning\n",
      "Successfully installed lightning-2.2.0.post0 lightning-utilities-0.10.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.3.101 nvidia-nvtx-cu12-12.1.105 pytorch-lightning-2.2.0.post0 torch-2.2.1 torchaudio-2.2.1 torchmetrics-1.3.1 torchvision-0.17.1 triton-2.2.0\n",
      "Looking in links: https://data.pyg.org/whl/torch-2.2.1+cu121.html\n",
      "Collecting torch-geometric\n",
      "  Using cached torch_geometric-2.5.0-py3-none-any.whl.metadata (64 kB)\n",
      "Collecting torch-sparse\n",
      "  Downloading https://data.pyg.org/whl/torch-2.2.0%2Bcu121/torch_sparse-0.6.18%2Bpt22cu121-cp38-cp38-linux_x86_64.whl (5.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torch-cluster\n",
      "  Downloading https://data.pyg.org/whl/torch-2.2.0%2Bcu121/torch_cluster-1.6.3%2Bpt22cu121-cp38-cp38-linux_x86_64.whl (3.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25hCollecting torch-scatter\n",
      "  Downloading https://data.pyg.org/whl/torch-2.2.0%2Bcu121/torch_scatter-2.1.2%2Bpt22cu121-cp38-cp38-linux_x86_64.whl (10.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m83.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting torch-spline-conv\n",
      "  Downloading https://data.pyg.org/whl/torch-2.2.0%2Bcu121/torch_spline_conv-1.2.2%2Bpt22cu121-cp38-cp38-linux_x86_64.whl (943 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m943.5/943.5 kB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from torch-geometric) (4.65.0)\n",
      "Requirement already satisfied: numpy in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from torch-geometric) (1.24.3)\n",
      "Requirement already satisfied: scipy in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from torch-geometric) (1.10.1)\n",
      "Requirement already satisfied: fsspec in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from torch-geometric) (2023.10.0)\n",
      "Requirement already satisfied: jinja2 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from torch-geometric) (3.1.3)\n",
      "Requirement already satisfied: aiohttp in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from torch-geometric) (3.9.3)\n",
      "Requirement already satisfied: requests in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from torch-geometric) (2.31.0)\n",
      "Requirement already satisfied: pyparsing in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from torch-geometric) (3.0.9)\n",
      "Requirement already satisfied: scikit-learn in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from torch-geometric) (1.3.0)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from torch-geometric) (5.9.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from aiohttp->torch-geometric) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from aiohttp->torch-geometric) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from aiohttp->torch-geometric) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from aiohttp->torch-geometric) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from aiohttp->torch-geometric) (1.9.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from aiohttp->torch-geometric) (4.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from jinja2->torch-geometric) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from requests->torch-geometric) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from requests->torch-geometric) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from requests->torch-geometric) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from requests->torch-geometric) (2024.2.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from scikit-learn->torch-geometric) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages (from scikit-learn->torch-geometric) (2.2.0)\n",
      "Using cached torch_geometric-2.5.0-py3-none-any.whl (1.1 MB)\n",
      "Installing collected packages: torch-spline-conv, torch-scatter, torch-sparse, torch-cluster, torch-geometric\n",
      "Successfully installed torch-cluster-1.6.3+pt22cu121 torch-geometric-2.5.0 torch-scatter-2.1.2+pt22cu121 torch-sparse-0.6.18+pt22cu121 torch-spline-conv-1.2.2+pt22cu121\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchaudio lightning torchmetrics\n",
    "!pip3 install \"torch-geometric\" \"torch-sparse\" \"torch-cluster\" \"torch-scatter\" \"torch-spline-conv\" -f https://data.pyg.org/whl/torch-2.2.1+cu121.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.1+cu121'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import urllib.request\n",
    "from urllib.error import HTTPError\n",
    "\n",
    "import lightning as L\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch_geometric\n",
    "import torch_geometric.data as geom_data\n",
    "import torch_geometric.nn as geom_nn\n",
    "\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "AVAIL_GPUS = min(1, torch.cuda.device_count())\n",
    "BATCH_SIZE = 256 if AVAIL_GPUS else 64\n",
    "# Path to the folder where the datasets are/should be downloaded\n",
    "DATASET_PATH = os.environ.get(\"PATH_DATASETS\", \"data/\")\n",
    "# Path to the folder where the pretrained models are saved\n",
    "CHECKPOINT_PATH = os.environ.get(\"PATH_CHECKPOINT\", \"saved_models/GNNs/\")\n",
    "\n",
    "# Setting the seed\n",
    "L.seed_everything(42)\n",
    "\n",
    "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial7/NodeLevelMLP.ckpt...\n",
      "Downloading https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial7/NodeLevelGNN.ckpt...\n",
      "Downloading https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial7/GraphLevelGraphConv.ckpt...\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial7/\"\n",
    "# Files to download\n",
    "pretrained_files = [\"NodeLevelMLP.ckpt\", \"NodeLevelGNN.ckpt\", \"GraphLevelGraphConv.ckpt\"]\n",
    "\n",
    "# Create checkpoint path if it doesn't exist yet\n",
    "os.makedirs(CHECKPOINT_PATH, exist_ok=True)\n",
    "\n",
    "# For each file, check whether it already exists. If not, try downloading it.\n",
    "for file_name in pretrained_files:\n",
    "    file_path = os.path.join(CHECKPOINT_PATH, file_name)\n",
    "    if \"/\" in file_name:\n",
    "        os.makedirs(file_path.rsplit(\"/\", 1)[0], exist_ok=True)\n",
    "    if not os.path.isfile(file_path):\n",
    "        file_url = base_url + file_name\n",
    "        print(\"Downloading %s...\" % file_url)\n",
    "        try:\n",
    "            urllib.request.urlretrieve(file_url, file_path)\n",
    "        except HTTPError as e:\n",
    "            print(\n",
    "                \"Something went wrong. Please try to download the file from the GDrive folder,\"\n",
    "                \" or contact the author with the full output including the following error:\\n\",\n",
    "                e,\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNLayer(nn.Module):\n",
    "    def __init__(self, c_in, c_out):\n",
    "        super().__init__()\n",
    "        self.projection = nn.Linear(c_in, c_out)\n",
    "\n",
    "    def forward(self, node_feats, adj_matrix):\n",
    "        \"\"\"Forward.\n",
    "\n",
    "        Args:\n",
    "            node_feats: Tensor with node features of shape [batch_size, num_nodes, c_in]\n",
    "            adj_matrix: Batch of adjacency matrices of the graph. If there is an edge from i to j,\n",
    "                         adj_matrix[b,i,j]=1 else 0. Supports directed edges by non-symmetric matrices.\n",
    "                         Assumes to already have added the identity connections.\n",
    "                         Shape: [batch_size, num_nodes, num_nodes]\n",
    "        \"\"\"\n",
    "        # Num neighbours = number of incoming edges\n",
    "        num_neighbours = adj_matrix.sum(dim=-1, keepdims=True)\n",
    "        node_feats = self.projection(node_feats)\n",
    "        node_feats = torch.bmm(adj_matrix, node_feats) # バッチごとの行列の積\n",
    "        node_feats = node_feats / num_neighbours\n",
    "        return node_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node features:\n",
      " tensor([[[0., 1.],\n",
      "         [2., 3.],\n",
      "         [4., 5.],\n",
      "         [6., 7.]]])\n",
      "\n",
      "Adjacency matrix:\n",
      " tensor([[[1., 1., 0., 0.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [0., 1., 1., 1.],\n",
      "         [0., 1., 1., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "node_feats = torch.arange(8, dtype=torch.float32).view(1, 4, 2)\n",
    "adj_matrix = Tensor([[\n",
    "    [1, 1, 0, 0], \n",
    "    [1, 1, 1, 1], \n",
    "    [0, 1, 1, 1], \n",
    "    [0, 1, 1, 1]]\n",
    "])\n",
    "\n",
    "print(\"Node features:\\n\", node_feats)\n",
    "print(\"\\nAdjacency matrix:\\n\", adj_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjacency matrix tensor([[[1., 1., 0., 0.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [0., 1., 1., 1.],\n",
      "         [0., 1., 1., 1.]]])\n",
      "Input features tensor([[[0., 1.],\n",
      "         [2., 3.],\n",
      "         [4., 5.],\n",
      "         [6., 7.]]])\n",
      "Output features tensor([[[1., 2.],\n",
      "         [3., 4.],\n",
      "         [4., 5.],\n",
      "         [4., 5.]]])\n"
     ]
    }
   ],
   "source": [
    "layer = GCNLayer(c_in=2, c_out=2)\n",
    "layer.projection.weight.data = Tensor([[1.0, 0.0], [0.0, 1.0]])\n",
    "layer.projection.bias.data = Tensor([0.0, 0.0])\n",
    "\n",
    "with torch.no_grad():\n",
    "    out_feats = layer(node_feats, adj_matrix)\n",
    "\n",
    "print(\"Adjacency matrix\", adj_matrix)\n",
    "print(\"Input features\", node_feats)\n",
    "print(\"Output features\", out_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATLayer(nn.Module):\n",
    "    def __init__(self, c_in, c_out, num_heads=1, concat_heads=True, alpha=0.2):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            c_in: Dimensionality of input features\n",
    "            c_out: Dimensionality of output features\n",
    "            num_heads: Number of heads, i.e. attention mechanisms to apply in parallel. The\n",
    "                        output features are equally split up over the heads if concat_heads=True.\n",
    "            concat_heads: If True, the output of the different heads is concatenated instead of averaged.\n",
    "            alpha: Negative slope of the LeakyReLU activation.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.concat_heads = concat_heads\n",
    "        if self.concat_heads:\n",
    "            assert c_out % num_heads == 0, \"Number of output features must be a multiple of the count of heads.\"\n",
    "            c_out = c_out // num_heads\n",
    "\n",
    "        # Sub-modules and parameters needed in the layer\n",
    "        self.projection = nn.Linear(c_in, c_out * num_heads)\n",
    "        self.a = nn.Parameter(Tensor(num_heads, 2 * c_out))  # One per head\n",
    "        self.leakyrelu = nn.LeakyReLU(alpha)\n",
    "\n",
    "        # Initialization from the original implementation\n",
    "        nn.init.xavier_uniform_(self.projection.weight.data, gain=1.414)\n",
    "        nn.init.xavier_uniform_(self.a.data, gain=1.414)\n",
    "\n",
    "    def forward(self, node_feats, adj_matrix, print_attn_probs=False):\n",
    "        \"\"\"Forward.\n",
    "\n",
    "        Args:\n",
    "            node_feats: Input features of the node. Shape: [batch_size, c_in]\n",
    "            adj_matrix: Adjacency matrix including self-connections. Shape: [batch_size, num_nodes, num_nodes]\n",
    "            print_attn_probs: If True, the attention weights are printed during the forward pass\n",
    "                               (for debugging purposes)\n",
    "        \"\"\"\n",
    "        batch_size, num_nodes = node_feats.size(0), node_feats.size(1)\n",
    "\n",
    "        # Apply linear layer and sort nodes by head\n",
    "        node_feats = self.projection(node_feats)\n",
    "        node_feats = node_feats.view(batch_size, num_nodes, self.num_heads, -1)\n",
    "\n",
    "        # We need to calculate the attention logits for every edge in the adjacency matrix\n",
    "        # Doing this on all possible combinations of nodes is very expensive\n",
    "        # => Create a tensor of [W*h_i||W*h_j] with i and j being the indices of all edges\n",
    "        # Returns indices where the adjacency matrix is not 0 => edges\n",
    "        edges = adj_matrix.nonzero(as_tuple=False)\n",
    "        node_feats_flat = node_feats.view(batch_size * num_nodes, self.num_heads, -1)\n",
    "        edge_indices_row = edges[:, 0] * num_nodes + edges[:, 1]\n",
    "        edge_indices_col = edges[:, 0] * num_nodes + edges[:, 2]\n",
    "        a_input = torch.cat(\n",
    "            [\n",
    "                torch.index_select(input=node_feats_flat, index=edge_indices_row, dim=0),\n",
    "                torch.index_select(input=node_feats_flat, index=edge_indices_col, dim=0),\n",
    "            ],\n",
    "            dim=-1,\n",
    "        )  # Index select returns a tensor with node_feats_flat being indexed at the desired positions\n",
    "\n",
    "        # Calculate attention MLP output (independent for each head)\n",
    "        attn_logits = torch.einsum(\"bhc,hc->bh\", a_input, self.a)\n",
    "        attn_logits = self.leakyrelu(attn_logits)\n",
    "\n",
    "        # Map list of attention values back into a matrix\n",
    "        attn_matrix = attn_logits.new_zeros(adj_matrix.shape + (self.num_heads,)).fill_(-9e15)\n",
    "        attn_matrix[adj_matrix[..., None].repeat(1, 1, 1, self.num_heads) == 1] = attn_logits.reshape(-1)\n",
    "\n",
    "        # Weighted average of attention\n",
    "        attn_probs = F.softmax(attn_matrix, dim=2)\n",
    "        if print_attn_probs:\n",
    "            print(\"Attention probs\\n\", attn_probs.permute(0, 3, 1, 2))\n",
    "        node_feats = torch.einsum(\"bijh,bjhc->bihc\", attn_probs, node_feats)\n",
    "\n",
    "        # If heads should be concatenated, we can do this by reshaping. Otherwise, take mean\n",
    "        if self.concat_heads:\n",
    "            node_feats = node_feats.reshape(batch_size, num_nodes, -1)\n",
    "        else:\n",
    "            node_feats = node_feats.mean(dim=2)\n",
    "\n",
    "        return node_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention probs\n",
      " tensor([[[[0.3543, 0.6457, 0.0000, 0.0000],\n",
      "          [0.1096, 0.1450, 0.2642, 0.4813],\n",
      "          [0.0000, 0.1858, 0.2885, 0.5257],\n",
      "          [0.0000, 0.2391, 0.2696, 0.4913]],\n",
      "\n",
      "         [[0.5100, 0.4900, 0.0000, 0.0000],\n",
      "          [0.2975, 0.2436, 0.2340, 0.2249],\n",
      "          [0.0000, 0.3838, 0.3142, 0.3019],\n",
      "          [0.0000, 0.4018, 0.3289, 0.2693]]]])\n",
      "Adjacency matrix tensor([[[1., 1., 0., 0.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [0., 1., 1., 1.],\n",
      "         [0., 1., 1., 1.]]])\n",
      "Input features tensor([[[0., 1.],\n",
      "         [2., 3.],\n",
      "         [4., 5.],\n",
      "         [6., 7.]]])\n",
      "Output features tensor([[[1.2913, 1.9800],\n",
      "         [4.2344, 3.7725],\n",
      "         [4.6798, 4.8362],\n",
      "         [4.5043, 4.7351]]])\n"
     ]
    }
   ],
   "source": [
    "layer = GATLayer(2, 2, num_heads=2)\n",
    "layer.projection.weight.data = Tensor([[1.0, 0.0], [0.0, 1.0]])\n",
    "layer.projection.bias.data = Tensor([0.0, 0.0])\n",
    "layer.a.data = Tensor([[-0.2, 0.3], [0.1, -0.1]])\n",
    "\n",
    "with torch.no_grad():\n",
    "    out_feats = layer(node_feats, adj_matrix, print_attn_probs=True)\n",
    "\n",
    "print(\"Adjacency matrix\", adj_matrix)\n",
    "print(\"Input features\", node_feats)\n",
    "print(\"Output features\", out_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn_layer_by_name = {\"GCN\": geom_nn.GCNConv, \"GAT\": geom_nn.GATConv, \"GraphConv\": geom_nn.GraphConv}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node-level tasks: Semi-supervised node classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "cora_dataset = torch_geometric.datasets.Planetoid(root=DATASET_PATH, name=\"Cora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cora_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        c_in,\n",
    "        c_hidden,\n",
    "        c_out,\n",
    "        num_layers=2,\n",
    "        layer_name=\"GCN\",\n",
    "        dp_rate=0.1,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"GNNModel.\n",
    "\n",
    "        Args:\n",
    "            c_in: Dimension of input features\n",
    "            c_hidden: Dimension of hidden features\n",
    "            c_out: Dimension of the output features. Usually number of classes in classification\n",
    "            num_layers: Number of \"hidden\" graph layers\n",
    "            layer_name: String of the graph layer to use\n",
    "            dp_rate: Dropout rate to apply throughout the network\n",
    "            kwargs: Additional arguments for the graph layer (e.g. number of heads for GAT)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        gnn_layer = gnn_layer_by_name[layer_name]\n",
    "\n",
    "        layers = []\n",
    "        in_channels, out_channels = c_in, c_hidden\n",
    "        for l_idx in range(num_layers - 1):\n",
    "            layers += [\n",
    "                gnn_layer(in_channels=in_channels, out_channels=out_channels, **kwargs),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(dp_rate),\n",
    "            ]\n",
    "            in_channels = c_hidden\n",
    "        layers += [gnn_layer(in_channels=in_channels, out_channels=c_out, **kwargs)]\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        \"\"\"Forward.\n",
    "\n",
    "        Args:\n",
    "            x: Input features per node\n",
    "            edge_index: List of vertex index pairs representing the edges in the graph (PyTorch geometric notation)\n",
    "        \"\"\"\n",
    "        for layer in self.layers:\n",
    "            # For graph layers, we need to add the \"edge_index\" tensor as additional input\n",
    "            # All PyTorch Geometric graph layer inherit the class \"MessagePassing\", hence\n",
    "            # we can simply check the class type.\n",
    "            if isinstance(layer, geom_nn.MessagePassing):\n",
    "                x = layer(x, edge_index)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nodeごとに独立したMLPを作り、ベースラインとする\n",
    "class MLPModel(nn.Module):\n",
    "    def __init__(self, c_in, c_hidden, c_out, num_layers=2, dp_rate=0.1):\n",
    "        \"\"\"MLPModel.\n",
    "\n",
    "        Args:\n",
    "            c_in: Dimension of input features\n",
    "            c_hidden: Dimension of hidden features\n",
    "            c_out: Dimension of the output features. Usually number of classes in classification\n",
    "            num_layers: Number of hidden layers\n",
    "            dp_rate: Dropout rate to apply throughout the network\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        in_channels, out_channels = c_in, c_hidden\n",
    "        for l_idx in range(num_layers - 1):\n",
    "            layers += [nn.Linear(in_channels, out_channels), nn.ReLU(inplace=True), nn.Dropout(dp_rate)]\n",
    "            in_channels = c_hidden\n",
    "        layers += [nn.Linear(in_channels, c_out)]\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, *args, **kwargs):\n",
    "        \"\"\"Forward.\n",
    "\n",
    "        Args:\n",
    "            x: Input features per node\n",
    "        \"\"\"\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeLevelGNN(L.LightningModule):\n",
    "    def __init__(self, model_name, **model_kwargs):\n",
    "        super().__init__()\n",
    "        # Saving hyperparameters\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        if model_name == \"MLP\":\n",
    "            self.model = MLPModel(**model_kwargs)\n",
    "        else:\n",
    "            self.model = GNNModel(**model_kwargs)\n",
    "        self.loss_module = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, data, mode=\"train\"):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.model(x, edge_index)\n",
    "\n",
    "        # Only calculate the loss on the nodes corresponding to the mask\n",
    "        if mode == \"train\":\n",
    "            mask = data.train_mask\n",
    "        elif mode == \"val\":\n",
    "            mask = data.val_mask\n",
    "        elif mode == \"test\":\n",
    "            mask = data.test_mask\n",
    "        else:\n",
    "            assert False, \"Unknown forward mode: %s\" % mode\n",
    "\n",
    "        loss = self.loss_module(x[mask], data.y[mask])\n",
    "        acc = (x[mask].argmax(dim=-1) == data.y[mask]).sum().float() / mask.sum()\n",
    "        return loss, acc\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # We use SGD here, but Adam works as well\n",
    "        optimizer = optim.SGD(self.parameters(), lr=0.1, momentum=0.9, weight_decay=2e-3)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, acc = self.forward(batch, mode=\"train\")\n",
    "        self.log(\"train_loss\", loss)\n",
    "        self.log(\"train_acc\", acc)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        _, acc = self.forward(batch, mode=\"val\")\n",
    "        self.log(\"val_acc\", acc)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        _, acc = self.forward(batch, mode=\"test\")\n",
    "        self.log(\"test_acc\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_node_classifier(model_name, dataset, **model_kwargs):\n",
    "    L.seed_everything(42)\n",
    "    node_data_loader = geom_data.DataLoader(dataset, batch_size=1)\n",
    "\n",
    "    # Create a PyTorch Lightning trainer\n",
    "    root_dir = os.path.join(CHECKPOINT_PATH, \"NodeLevel\" + model_name)\n",
    "    os.makedirs(root_dir, exist_ok=True)\n",
    "    trainer = L.Trainer(\n",
    "        default_root_dir=root_dir,\n",
    "        callbacks=[ModelCheckpoint(save_weights_only=True, mode=\"max\", monitor=\"val_acc\")],\n",
    "        accelerator=\"auto\",\n",
    "        devices=AVAIL_GPUS,\n",
    "        max_epochs=200,\n",
    "        enable_progress_bar=False,\n",
    "    )  # 0 because epoch size is 1\n",
    "    trainer.logger._default_hp_metric = None  # Optional logging argument that we don't need\n",
    "\n",
    "    # Check whether pretrained model exists. If yes, load it and skip training\n",
    "    pretrained_filename = os.path.join(CHECKPOINT_PATH, \"NodeLevel%s.ckpt\" % model_name)\n",
    "    if os.path.isfile(pretrained_filename):\n",
    "        print(\"Found pretrained model, loading...\")\n",
    "        model = NodeLevelGNN.load_from_checkpoint(pretrained_filename)\n",
    "    else:\n",
    "        L.seed_everything()\n",
    "        model = NodeLevelGNN(\n",
    "            model_name=model_name, c_in=dataset.num_node_features, c_out=dataset.num_classes, **model_kwargs\n",
    "        )\n",
    "        trainer.fit(model, node_data_loader, node_data_loader)\n",
    "        model = NodeLevelGNN.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)\n",
    "\n",
    "    # Test best model on the test set\n",
    "    test_result = trainer.test(model, dataloaders=node_data_loader, verbose=False)\n",
    "    batch = next(iter(node_data_loader))\n",
    "    batch = batch.to(model.device)\n",
    "    _, train_acc = model.forward(batch, mode=\"train\")\n",
    "    _, val_acc = model.forward(batch, mode=\"val\")\n",
    "    result = {\"train\": train_acc, \"val\": val_acc, \"test\": test_result[0][\"test_acc\"]}\n",
    "    return model, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small function for printing the test scores\n",
    "def print_results(result_dict):\n",
    "    if \"train\" in result_dict:\n",
    "        print(\"Train accuracy: %4.2f%%\" % (100.0 * result_dict[\"train\"]))\n",
    "    if \"val\" in result_dict:\n",
    "        print(\"Val accuracy:   %4.2f%%\" % (100.0 * result_dict[\"val\"]))\n",
    "    print(\"Test accuracy:  %4.2f%%\" % (100.0 * result_dict[\"test\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "/home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found pretrained model, loading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.0.2 to v2.2.0.post0. To apply the upgrade to your files permanently, run `python -m lightning.pytorch.utilities.upgrade_checkpoint saved_models/GNNs/NodeLevelMLP.ckpt`\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Missing logger folder: saved_models/GNNs/NodeLevelMLP/lightning_logs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 97.14%\n",
      "Val accuracy:   54.60%\n",
      "Test accuracy:  60.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n",
      "/home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages/lightning/pytorch/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 2708. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    }
   ],
   "source": [
    "node_mlp_model, node_mlp_result = train_node_classifier(\n",
    "    model_name=\"MLP\", dataset=cora_dataset, c_hidden=16, num_layers=2, dp_rate=0.1\n",
    ")\n",
    "\n",
    "print_results(node_mlp_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "/home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/pytorch_gnn_20240304/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.0.2 to v2.2.0.post0. To apply the upgrade to your files permanently, run `python -m lightning.pytorch.utilities.upgrade_checkpoint saved_models/GNNs/NodeLevelGNN.ckpt`\n",
      "Missing logger folder: saved_models/GNNs/NodeLevelGNN/lightning_logs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found pretrained model, loading...\n",
      "Train accuracy: 100.00%\n",
      "Val accuracy:   78.60%\n",
      "Test accuracy:  82.40%\n"
     ]
    }
   ],
   "source": [
    "node_gnn_model, node_gnn_result = train_node_classifier(\n",
    "    model_name=\"GNN\", layer_name=\"GCN\", dataset=cora_dataset, c_hidden=16, num_layers=2, dp_rate=0.1\n",
    ")\n",
    "print_results(node_gnn_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_nlp_lstm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
